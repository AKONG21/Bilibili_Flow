name: Weekly Historical Data Processing

on:
  schedule:
    # UTC 时间 18:07 每月第四个周四 = 北京时间每月第四个周五凌晨2:07 (避免冲突)
    - cron: '7 18 * * 4#4'
  workflow_dispatch:

jobs:
  check-run-week:
    runs-on: ubuntu-latest
    outputs:
      should_run: ${{ steps.check-week.outputs.should_run }}
    steps:
      - name: Check if this is the 4th Thursday of the month (UTC)
        id: check-week
        run: |
          # 获取当前日期信息
          CURRENT_MONTH=$(date +'%m')
          CURRENT_YEAR=$(date +'%Y')
          CURRENT_DAY=$(date +'%d')
          
          # 计算当前是本月的第几个周四
          # 获取本月1号是周几 (0=周日,1=周一,...,6=周六)
          FIRST_DAY_OF_MONTH=$(date -d "$CURRENT_YEAR-$CURRENT_MONTH-01" +'%w' 2>/dev/null || date -j -f "%Y-%m-%d" "$CURRENT_YEAR-$CURRENT_MONTH-01" +'%w')
          
          # 计算本月第一个周四是几号
          DAYS_UNTIL_FIRST_THURSDAY=$((4 - FIRST_DAY_OF_MONTH))
          if [ $DAYS_UNTIL_FIRST_THURSDAY -le 0 ]; then
            DAYS_UNTIL_FIRST_THURSDAY=$((DAYS_UNTIL_FIRST_THURSDAY + 7))
          fi
          FIRST_THURSDAY=$((1 + DAYS_UNTIL_FIRST_THURSDAY))
          
          # 计算本月第四个周四是几号
          FOURTH_THURSDAY=$((FIRST_THURSDAY + 21))
          
          # 检查当前日期是否是本月第四个周四
          if [ "$CURRENT_DAY" -eq "$FOURTH_THURSDAY" ] || [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            echo "This is the 4th Thursday of the month or manual trigger, should run"
            echo "should_run=true" >> $GITHUB_OUTPUT
          else
            echo "Not the 4th Thursday of the month, skipping run"
            echo "should_run=false" >> $GITHUB_OUTPUT
          fi
          
          echo "Current date: $CURRENT_YEAR-$CURRENT_MONTH-$CURRENT_DAY"
          echo "First Thursday: $FIRST_THURSDAY, Fourth Thursday: $FOURTH_THURSDAY"
          
          echo "Current Year-Week: $YEAR_WEEK, Week number: $WEEK_NUM, Remainder: $REMAINDER"
  
  weekly-historical-processing:
    needs: check-run-week
    if: ${{ needs.check-run-week.outputs.should_run == 'true' }}
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Install Playwright browsers
      run: |
        playwright install chromium
        
    - name: Configure git
      run: |
        git config --global user.name "GitHub Actions"
        git config --global user.email "actions@github.com"
        
    - name: Debug environment and configuration
      env:
        BILIBILI_COOKIES: ${{ secrets.BILIBILI_COOKIES }}
        BILIBILI_COOKIES_1: ${{ secrets.BILIBILI_COOKIES_1 }}
        BILIBILI_COOKIES_2: ${{ secrets.BILIBILI_COOKIES_2 }}
        BILIBILI_COOKIES_3: ${{ secrets.BILIBILI_COOKIES_3 }}
        BILIBILI_COOKIES_4: ${{ secrets.BILIBILI_COOKIES_4 }}
        BILIBILI_COOKIES_5: ${{ secrets.BILIBILI_COOKIES_5 }}
        BILIBILI_COOKIES_6: ${{ secrets.BILIBILI_COOKIES_6 }}
        BILIBILI_COOKIES_7: ${{ secrets.BILIBILI_COOKIES_7 }}
        BILIBILI_COOKIES_8: ${{ secrets.BILIBILI_COOKIES_8 }}
        BILIBILI_COOKIES_9: ${{ secrets.BILIBILI_COOKIES_9 }}
        BILIBILI_COOKIES_10: ${{ secrets.BILIBILI_COOKIES_10 }}
      run: |
        echo "🔍 Running environment debug check"
        python .github/scripts/debug_data_collection.py
        
    - name: Enhanced cookie rotation and selection
      env:
        BILIBILI_COOKIES: ${{ secrets.BILIBILI_COOKIES }}
        BILIBILI_COOKIES_1: ${{ secrets.BILIBILI_COOKIES_1 }}
        BILIBILI_COOKIES_2: ${{ secrets.BILIBILI_COOKIES_2 }}
        BILIBILI_COOKIES_3: ${{ secrets.BILIBILI_COOKIES_3 }}
        BILIBILI_COOKIES_4: ${{ secrets.BILIBILI_COOKIES_4 }}
        BILIBILI_COOKIES_5: ${{ secrets.BILIBILI_COOKIES_5 }}
        BILIBILI_COOKIES_6: ${{ secrets.BILIBILI_COOKIES_6 }}
        BILIBILI_COOKIES_7: ${{ secrets.BILIBILI_COOKIES_7 }}
        BILIBILI_COOKIES_8: ${{ secrets.BILIBILI_COOKIES_8 }}
        BILIBILI_COOKIES_9: ${{ secrets.BILIBILI_COOKIES_9 }}
        BILIBILI_COOKIES_10: ${{ secrets.BILIBILI_COOKIES_10 }}
      run: |
        echo "🔄 Starting enhanced cookie rotation with fallback mechanism"
        python .github/scripts/enhanced_cookie_rotation.py
        
    - name: Cookie cleanup check
      if: always()
      run: |
        echo "🗑️ Checking for failed cookies cleanup"
        python .github/scripts/cookie_cleanup_manager.py || echo "Cleanup check completed with warnings"
        
    - name: Run monthly historical data processing with enhanced notification
      env:
        FEISHU_WEBHOOK_URL: ${{ secrets.FEISHU_WEBHOOK_URL }}
        PYTHONPATH: ${{ github.workspace }}
      run: |
        echo "Starting weekly historical data processing with enhanced notification"
        echo "Current working directory: $(pwd)"
        echo "Python path: $PYTHONPATH"
        echo "Contents of current directory:"
        ls -la
        
        # 直接运行月任务，不通过 feishu_notifier
        if ! python run_monthly_task.py; then
          echo "❌ Monthly task execution failed"
          echo "Checking for any generated files:"
          find . -name "*.json" -o -name "*.db" | head -10
          exit 1
        else
          echo "✅ Monthly task execution completed"
          echo "Checking generated data files:"
          find data/ -type f | head -10
        fi
        
    - name: Commit and push data
      run: |
        echo "🔍 Checking for changes in data directory"
        
        # Force add all data subdirectories to ensure new files are tracked
        if [ -d "data/" ]; then
          git add -A data/
          
          # Check if there are changes to commit
          if ! git diff --staged --quiet; then
            git commit -m "📊 Weekly historical data processing - $(date +'%Y-%m-%d %H:%M:%S')"
            git push
            echo "✅ Data committed and pushed successfully"
          else
            echo "ℹ️ No changes to commit in data directory"
          fi
        else
          echo "⚠️ Data directory doesn't exist - no data to commit"
        fi
        
    - name: Generate data summary report
      if: always()
      run: |
        echo "## Weekly Data Processing Report - $(date +'%Y-%m-%d')" > weekly_report.md
        echo "### Processing Summary" >> weekly_report.md
        
        # Check if data directory exists and has content
        if [ -d "data/" ] && [ "$(find data/ -name "*.json" | wc -l)" -gt 0 ]; then
          echo "- ✅ Data directory found with JSON files" >> weekly_report.md
          echo "- ✅ Historical data processing appears successful" >> weekly_report.md
          echo "- ✅ 28-day segmentation applied" >> weekly_report.md
          echo "- ✅ Database baseline established" >> weekly_report.md
        else
          echo "- ❌ Historical data processing encountered errors" >> weekly_report.md
          echo "- ⚠️ Data directory empty or missing JSON files" >> weekly_report.md
          echo "- ⚠️ Check workflow logs for details" >> weekly_report.md
        fi
        
        echo "" >> weekly_report.md
        echo "### File Structure" >> weekly_report.md
        if [ -d "data/" ]; then
          echo "Data directory contents:" >> weekly_report.md
          find data/ -type f -name "*.json" | head -20 | while read file; do
            size=$(stat -f%z "$file" 2>/dev/null || stat -c%s "$file" 2>/dev/null || echo "unknown")
            echo "- $file (${size} bytes)" >> weekly_report.md
          done
          
          if [ "$(find data/ -name "*.json" | wc -l)" -eq 0 ]; then
            echo "- No JSON files found in data directory" >> weekly_report.md
          fi
        else
          echo "- Data directory not found" >> weekly_report.md
        fi
        
        echo "" >> weekly_report.md
        echo "### System Information" >> weekly_report.md
        echo "- Workflow: weekly-historical-processing" >> weekly_report.md
        echo "- Runner: ubuntu-latest" >> weekly_report.md
        echo "- Python version: 3.11" >> weekly_report.md
        echo "- Timestamp: $(date -u +'%Y-%m-%d %H:%M:%S UTC')" >> weekly_report.md
        
        # Create placeholder files if they don't exist
        touch cookie_management_report.json
        touch cookie_cleanup_report.json  
        touch failed_cookies_report.json
        touch cleanup_cookies.sh
        
        # Add basic content to empty files with timestamps
        timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
        [ ! -s cookie_management_report.json ] && echo "{\"status\": \"no_report_generated\", \"timestamp\": \"$timestamp\", \"workflow\": \"weekly-historical\"}" > cookie_management_report.json
        [ ! -s cookie_cleanup_report.json ] && echo "{\"status\": \"no_cleanup_performed\", \"timestamp\": \"$timestamp\", \"workflow\": \"weekly-historical\"}" > cookie_cleanup_report.json
        [ ! -s failed_cookies_report.json ] && echo "{\"failed_cookies\": [], \"timestamp\": \"$timestamp\", \"workflow\": \"weekly-historical\"}" > failed_cookies_report.json
        [ ! -s cleanup_cookies.sh ] && echo "#!/bin/bash\necho \"No cleanup script generated for weekly-historical workflow - $timestamp\"" > cleanup_cookies.sh
        
    - name: Upload report and cookie reports
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: weekly-report-${{ github.run_number }}
        path: |
          weekly_report.md
          debug_report.json
          cookie_management_report.json
          cookie_cleanup_report.json
          failed_cookies_report.json
          cleanup_cookies.sh
        retention-days: 30
