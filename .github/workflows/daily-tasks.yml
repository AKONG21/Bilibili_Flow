name: Daily Data Collection (08:07 & 20:07)

on:
  schedule:
    # UTC æ—¶é—´ 00:07 = åŒ—äº¬æ—¶é—´ 08:07
    - cron: '7 0 * * *'
    # UTC æ—¶é—´ 12:07 = åŒ—äº¬æ—¶é—´ 20:07
    - cron: '7 12 * * *'
  workflow_dispatch:

permissions:
  contents: write
  actions: read

jobs:
  daily-data-collection:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Install Playwright browsers
      run: |
        playwright install chromium
        
    - name: Configure git
      run: |
        git config --global user.name "GitHub Actions"
        git config --global user.email "actions@github.com"
        
    - name: Enhanced cookie rotation and selection
      env:
        UP_ID: ${{ secrets.UP_ID }}
        BILIBILI_COOKIES: ${{ secrets.BILIBILI_COOKIES }}
        BILIBILI_COOKIES_1: ${{ secrets.BILIBILI_COOKIES_1 }}
        BILIBILI_COOKIES_2: ${{ secrets.BILIBILI_COOKIES_2 }}
        BILIBILI_COOKIES_3: ${{ secrets.BILIBILI_COOKIES_3 }}
        BILIBILI_COOKIES_4: ${{ secrets.BILIBILI_COOKIES_4 }}
        BILIBILI_COOKIES_5: ${{ secrets.BILIBILI_COOKIES_5 }}
        BILIBILI_COOKIES_6: ${{ secrets.BILIBILI_COOKIES_6 }}
        BILIBILI_COOKIES_7: ${{ secrets.BILIBILI_COOKIES_7 }}
        BILIBILI_COOKIES_8: ${{ secrets.BILIBILI_COOKIES_8 }}
        BILIBILI_COOKIES_9: ${{ secrets.BILIBILI_COOKIES_9 }}
        BILIBILI_COOKIES_10: ${{ secrets.BILIBILI_COOKIES_10 }}
      run: |
        echo "ðŸ”„ Starting enhanced cookie rotation with fallback mechanism"
        python .github/scripts/enhanced_cookie_rotation.py
        
    - name: Cookie cleanup check
      if: always()
      run: |
        echo "ðŸ—‘ï¸ Checking for failed cookies cleanup"
        python .github/scripts/cookie_cleanup_manager.py || echo "Cleanup check completed with warnings"
        
    - name: Run daily data collection with enhanced notification
      env:
        UP_ID: ${{ secrets.UP_ID }}
        FEISHU_WEBHOOK_URL: ${{ secrets.FEISHU_WEBHOOK_URL }}
        PYTHONPATH: ${{ github.workspace }}
      run: |
        echo "Starting daily data collection with enhanced notification"
        echo "Current working directory: $(pwd)"
        echo "Python path: $PYTHONPATH"
        
        # æ ¹æ®æ—¶é—´åˆ¤æ–­æ˜¯æ—©æ™¨è¿˜æ˜¯æ™šé—´ä»»åŠ¡
        CURRENT_HOUR=$(date -u +%H)
        if [ "$CURRENT_HOUR" = "00" ]; then
          TASK_TYPE="æ—©æ™¨"
          TASK_EMOJI="ðŸŒ…"
        else
          TASK_TYPE="æ™šé—´"  
          TASK_EMOJI="ðŸŒ™"
        fi
        
        # è¿è¡Œæ—¥ä»»åŠ¡å¹¶è®°å½•ç»“æžœ
        TASK_START_TIME=$(date +%s)
        TASK_OUTPUT=$(python run_daily_task.py 2>&1)
        TASK_EXIT_CODE=$?
        TASK_END_TIME=$(date +%s)
        TASK_DURATION=$((TASK_END_TIME - TASK_START_TIME))
        
        # ä»Žè¾“å‡ºä¸­æå–ä¿¡æ¯
        TOTAL_COOKIES=$(echo "$TASK_OUTPUT" | grep -oP 'total_cookies["\s]*:["\s]*\K\d+' | tail -1 || echo "0")
        USEABLE_COOKIES=$(echo "$TASK_OUTPUT" | grep -oP 'useable_cookies["\s]*:["\s]*\K\d+' | tail -1 || echo "0")
        ACTIVE_COOKIE=$(echo "$TASK_OUTPUT" | grep -oP 'active_cookie["\s]*:["\s]*["\']\K[^"\']+'| tail -1 || echo "æœªçŸ¥")
        COOKIE_INFO=$(echo "$TASK_OUTPUT" | grep -oP 'cookie_info["\s]*:["\s]*["\']\K[^"\']+'| tail -1 || echo "æœªçŸ¥")
        UP_NAME=$(echo "$TASK_OUTPUT" | grep -oP 'up_name["\s]*:["\s]*["\']\K[^"\']+'| tail -1 || echo "æœªçŸ¥")
        TOTAL_VIDEOS=$(echo "$TASK_OUTPUT" | grep -oP 'total_videos["\s]*:["\s]*\K\d+' | tail -1 || echo "0")
        TOTAL_COMMENTS=$(echo "$TASK_OUTPUT" | grep -oP 'total_comments["\s]*:["\s]*\K\d+' | tail -1 || echo "0")
        ERRORS_COUNT=$(echo "$TASK_OUTPUT" | grep -oP 'errors_count["\s]*:["\s]*\K\d+' | tail -1 || echo "0")
        
        if [ $TASK_EXIT_CODE -ne 0 ]; then
          echo "âŒ ${TASK_TYPE} data collection failed"
          echo "Checking for any generated files:"
          find . -name "*.json" -o -name "*.db" | head -10
          
          # å‘é€å¤±è´¥é€šçŸ¥
          if [ -n "$FEISHU_WEBHOOK_URL" ]; then
            ERROR_TEXT="âŒ ${TASK_TYPE}æ•°æ®é‡‡é›†å¤±è´¥\\næ—¶é—´: $(date '+%Y-%m-%d %H:%M:%S')\\nè¿è¡Œ: #${{ github.run_number }}\\nåˆ†æ”¯: ${{ github.ref_name }}\\n\\nðŸ“Š CookieçŠ¶æ€:\\ntotal_cookies: $TOTAL_COOKIES\\nuseable_cookies: $USEABLE_COOKIES\\nactive_cookie: $ACTIVE_COOKIE\\ncookie_info: $COOKIE_INFO\\n\\nðŸ“ˆ ä»»åŠ¡ç»Ÿè®¡:\\nup_name: $UP_NAME\\ntotal_videos: $TOTAL_VIDEOS\\ntotal_comments: $TOTAL_COMMENTS\\nerrors_count: $ERRORS_COUNT\\nduration_seconds: $TASK_DURATION\\n\\nè¯·æŸ¥çœ‹å·¥ä½œæµæ—¥å¿—"
            curl -X POST -H "Content-Type: application/json" \
              -d "{\"msg_type\":\"text\",\"content\":{\"text\":\"$ERROR_TEXT\"}}" \
              "$FEISHU_WEBHOOK_URL" || echo "é£žä¹¦é€šçŸ¥å‘é€å¤±è´¥"
          fi
          exit 1
        else
          echo "âœ… ${TASK_TYPE} data collection completed"
          echo "Checking generated data files:"
          find data/ -type f | head -10
          
          # ç»Ÿè®¡ç”Ÿæˆçš„æ–‡ä»¶
          JSON_COUNT=$(find data/ -name "*.json" | wc -l)
          TOTAL_SIZE=$(du -sh data/ 2>/dev/null | cut -f1 || echo "æœªçŸ¥")
          
          # å‘é€æˆåŠŸé€šçŸ¥
          if [ -n "$FEISHU_WEBHOOK_URL" ]; then
            SUCCESS_TEXT="âœ… ${TASK_TYPE}æ•°æ®é‡‡é›†æˆåŠŸ\\næ—¶é—´: $(date '+%Y-%m-%d %H:%M:%S')\\nè¿è¡Œ: #${{ github.run_number }}\\nåˆ†æ”¯: ${{ github.ref_name }}\\n\\nðŸ“Š CookieçŠ¶æ€:\\ntotal_cookies: $TOTAL_COOKIES\\nuseable_cookies: $USEABLE_COOKIES\\nactive_cookie: $ACTIVE_COOKIE\\ncookie_info: $COOKIE_INFO\\n\\nðŸ“ˆ ä»»åŠ¡ç»Ÿè®¡:\\nup_name: $UP_NAME\\ntotal_videos: $TOTAL_VIDEOS\\ntotal_comments: $TOTAL_COMMENTS\\nerrors_count: $ERRORS_COUNT\\nduration_seconds: $TASK_DURATION\\n\\nðŸ“ æ–‡ä»¶ä¿¡æ¯:\\nJSONæ–‡ä»¶: $JSON_COUNT ä¸ª\\næ•°æ®å¤§å°: $TOTAL_SIZE"
            curl -X POST -H "Content-Type: application/json" \
              -d "{\"msg_type\":\"text\",\"content\":{\"text\":\"$SUCCESS_TEXT\"}}" \
              "$FEISHU_WEBHOOK_URL" || echo "é£žä¹¦é€šçŸ¥å‘é€å¤±è´¥"
          fi
        fi
        
    - name: Commit and push data
      run: |
        # é‡æ–°å®šä¹‰æ—¶é—´ç›¸å…³å˜é‡
        CURRENT_HOUR=$(date -u +%H)
        if [ "$CURRENT_HOUR" = "00" ]; then
          TASK_TYPE="æ—©æ™¨"
          TASK_EMOJI="ðŸŒ…"
        else
          TASK_TYPE="æ™šé—´"  
          TASK_EMOJI="ðŸŒ™"
        fi
        
        # Check if data directory exists and has files
        if [ -d "data/" ] && [ "$(find data/ -type f | wc -l)" -gt 0 ]; then
          git add data/
          if ! git diff --staged --quiet; then
            git commit -m "${TASK_EMOJI} ${TASK_TYPE} data collection - $(date +'%Y-%m-%d %H:%M:%S')"
            git push
            echo "âœ… Data committed and pushed successfully"
          else
            echo "â„¹ï¸ No changes to commit in data directory"
          fi
        else
          echo "âš ï¸ Data directory is empty or doesn't exist - no data to commit"
        fi
        
    - name: Prepare and upload cookie management reports
      if: always()
      run: |
        # Create placeholder files if they don't exist
        touch cookie_management_report.json
        touch cookie_cleanup_report.json  
        touch failed_cookies_report.json
        touch cleanup_cookies.sh
        
        # Add basic content to empty files
        [ ! -s cookie_management_report.json ] && echo '{"status": "no_report_generated", "timestamp": "'$(date -u +"%Y-%m-%dT%H:%M:%SZ")'"}' > cookie_management_report.json
        [ ! -s cookie_cleanup_report.json ] && echo '{"status": "no_cleanup_performed", "timestamp": "'$(date -u +"%Y-%m-%dT%H:%M:%SZ")'"}' > cookie_cleanup_report.json
        [ ! -s failed_cookies_report.json ] && echo '{"failed_cookies": [], "timestamp": "'$(date -u +"%Y-%m-%dT%H:%M:%SZ")'"}' > failed_cookies_report.json
        [ ! -s cleanup_cookies.sh ] && echo '#!/bin/bash\necho "No cleanup script generated - '$(date)'"' > cleanup_cookies.sh
        
    - name: Upload cookie management reports
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: cookie-reports-daily-${{ github.run_number }}
        path: |
          cookie_management_report.json
          cookie_cleanup_report.json
          failed_cookies_report.json
          cleanup_cookies.sh
        retention-days: 30