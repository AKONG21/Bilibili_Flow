name: Daily Data Collection (08:07 & 20:07)

on:
  schedule:
    # UTC æ—¶é—´ 00:07 = åŒ—äº¬æ—¶é—´ 08:07
    - cron: '7 0 * * *'
    # UTC æ—¶é—´ 12:07 = åŒ—äº¬æ—¶é—´ 20:07
    - cron: '7 12 * * *'
  workflow_dispatch:

permissions:
  contents: write
  actions: read

jobs:
  daily-data-collection:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Install Playwright browsers
      run: |
        playwright install chromium
        
    - name: Configure git
      run: |
        git config --global user.name "GitHub Actions"
        git config --global user.email "actions@github.com"
        
    - name: Enhanced cookie rotation and selection
      env:
        UP_ID: ${{ secrets.UP_ID }}
        BILIBILI_COOKIES: ${{ secrets.BILIBILI_COOKIES }}
        BILIBILI_COOKIES_1: ${{ secrets.BILIBILI_COOKIES_1 }}
        BILIBILI_COOKIES_2: ${{ secrets.BILIBILI_COOKIES_2 }}
        BILIBILI_COOKIES_3: ${{ secrets.BILIBILI_COOKIES_3 }}
        BILIBILI_COOKIES_4: ${{ secrets.BILIBILI_COOKIES_4 }}
        BILIBILI_COOKIES_5: ${{ secrets.BILIBILI_COOKIES_5 }}
        BILIBILI_COOKIES_6: ${{ secrets.BILIBILI_COOKIES_6 }}
        BILIBILI_COOKIES_7: ${{ secrets.BILIBILI_COOKIES_7 }}
        BILIBILI_COOKIES_8: ${{ secrets.BILIBILI_COOKIES_8 }}
        BILIBILI_COOKIES_9: ${{ secrets.BILIBILI_COOKIES_9 }}
        BILIBILI_COOKIES_10: ${{ secrets.BILIBILI_COOKIES_10 }}
      run: |
        echo "ðŸ”„ Starting enhanced cookie rotation with fallback mechanism"
        python .github/scripts/enhanced_cookie_rotation.py
        
    - name: Cookie cleanup check
      if: always()
      run: |
        echo "ðŸ—‘ï¸ Checking for failed cookies cleanup"
        python .github/scripts/cookie_cleanup_manager.py || echo "Cleanup check completed with warnings"
        
    - name: Run daily data collection
      env:
        UP_ID: ${{ secrets.UP_ID }}
        FEISHU_WEBHOOK_URL: ${{ secrets.FEISHU_WEBHOOK_URL }}
        PYTHONPATH: ${{ github.workspace }}
      run: |
        echo "Starting daily data collection"
        echo "Current working directory: $(pwd)"
        echo "Python path: $PYTHONPATH"
        
        # Determine task type based on UTC time
        CURRENT_HOUR=$(date -u +%H)
        if [ "$CURRENT_HOUR" = "00" ]; then
          TASK_TYPE="Morning"
          TASK_EMOJI="ðŸŒ…"
        else
          TASK_TYPE="Evening"
          TASK_EMOJI="ðŸŒ™"
        fi
        
        echo "Task type: $TASK_TYPE ($TASK_EMOJI)"
        
        # Run daily task and capture output
        echo "Running daily task..."
        TASK_START_TIME=$(date +%s)
        
        if python run_daily_task.py > task_output.log 2>&1; then
          TASK_EXIT_CODE=0
          echo "âœ… Daily task completed successfully"
        else
          TASK_EXIT_CODE=1
          echo "âŒ Daily task failed"
        fi
        
        TASK_END_TIME=$(date +%s)
        TASK_DURATION=$((TASK_END_TIME - TASK_START_TIME))
        
        # Display task output for debugging
        echo "=== Task Output ==="
        cat task_output.log
        echo "=================="
        
        # Extract information from task output using regex
        TASK_OUTPUT=$(cat task_output.log)
        TOTAL_COOKIES=$(echo "$TASK_OUTPUT" | grep -oE 'total_cookies[[:space:]]*:[[:space:]]*[0-9]+' | grep -oE '[0-9]+' | tail -1 || echo "0")
        USEABLE_COOKIES=$(echo "$TASK_OUTPUT" | grep -oE 'useable_cookies[[:space:]]*:[[:space:]]*[0-9]+' | grep -oE '[0-9]+' | tail -1 || echo "0")
        ACTIVE_COOKIE=$(echo "$TASK_OUTPUT" | grep -oE 'active_cookie[[:space:]]*:[[:space:]]*[^,}]+' | sed 's/.*:[[:space:]]*//' | sed 's/[",]//g' | tail -1 || echo "Unknown")
        COOKIE_INFO=$(echo "$TASK_OUTPUT" | grep -oE 'cookie_info[[:space:]]*:[[:space:]]*[^,}]+' | sed 's/.*:[[:space:]]*//' | sed 's/[",]//g' | tail -1 || echo "Unknown")
        UP_NAME=$(echo "$TASK_OUTPUT" | grep -oE 'up_name[[:space:]]*:[[:space:]]*[^,}]+' | sed 's/.*:[[:space:]]*//' | sed 's/[",]//g' | tail -1 || echo "Unknown")
        TOTAL_VIDEOS=$(echo "$TASK_OUTPUT" | grep -oE 'total_videos[[:space:]]*:[[:space:]]*[0-9]+' | grep -oE '[0-9]+' | tail -1 || echo "0")
        TOTAL_COMMENTS=$(echo "$TASK_OUTPUT" | grep -oE 'total_comments[[:space:]]*:[[:space:]]*[0-9]+' | grep -oE '[0-9]+' | tail -1 || echo "0")
        ERRORS_COUNT=$(echo "$TASK_OUTPUT" | grep -oE 'errors_count[[:space:]]*:[[:space:]]*[0-9]+' | grep -oE '[0-9]+' | tail -1 || echo "0")
        
        echo "Extracted metrics:"
        echo "- Total cookies: $TOTAL_COOKIES"
        echo "- Useable cookies: $USEABLE_COOKIES"
        echo "- Active cookie: $ACTIVE_COOKIE"
        echo "- Cookie info: $COOKIE_INFO"
        echo "- UP name: $UP_NAME"
        echo "- Total videos: $TOTAL_VIDEOS"
        echo "- Total comments: $TOTAL_COMMENTS"
        echo "- Errors count: $ERRORS_COUNT"
        echo "- Duration: $TASK_DURATION seconds"
        
        # Send notification based on task result
        if [ "$TASK_EXIT_CODE" -ne 0 ]; then
          echo "Sending failure notification..."
          if [ -n "$FEISHU_WEBHOOK_URL" ]; then
            ERROR_MSG="âŒ ${TASK_TYPE} Daily Data Collection Failed\\n\\nTime: $(date '+%Y-%m-%d %H:%M:%S')\\nRun: #${{ github.run_number }}\\nBranch: ${{ github.ref_name }}\\n\\nðŸ“Š Cookie Status:\\nTotal: ${TOTAL_COOKIES}\\nUseable: ${USEABLE_COOKIES}\\nActive: ${ACTIVE_COOKIE}\\nInfo: ${COOKIE_INFO}\\n\\nðŸ“ˆ Task Stats:\\nUP: ${UP_NAME}\\nVideos: ${TOTAL_VIDEOS}\\nComments: ${TOTAL_COMMENTS}\\nErrors: ${ERRORS_COUNT}\\nDuration: ${TASK_DURATION}s\\n\\nðŸ”— Check workflow logs for details"
            curl -X POST "$FEISHU_WEBHOOK_URL" \
              -H "Content-Type: application/json" \
              -d "{\"msg_type\":\"text\",\"content\":{\"text\":\"$ERROR_MSG\"}}" \
              || echo "Failed to send Feishu notification"
          fi
          exit 1
        else
          echo "Sending success notification..."
          # Count generated files
          JSON_COUNT=$(find data/ -name "*.json" 2>/dev/null | wc -l || echo "0")
          TOTAL_SIZE=$(du -sh data/ 2>/dev/null | cut -f1 || echo "Unknown")
          
          if [ -n "$FEISHU_WEBHOOK_URL" ]; then
            SUCCESS_MSG="âœ… ${TASK_TYPE} Daily Data Collection Success\\n\\nTime: $(date '+%Y-%m-%d %H:%M:%S')\\nRun: #${{ github.run_number }}\\nBranch: ${{ github.ref_name }}\\n\\nðŸ“Š Cookie Status:\\nTotal: ${TOTAL_COOKIES}\\nUseable: ${USEABLE_COOKIES}\\nActive: ${ACTIVE_COOKIE}\\nInfo: ${COOKIE_INFO}\\n\\nðŸ“ˆ Task Stats:\\nUP: ${UP_NAME}\\nVideos: ${TOTAL_VIDEOS}\\nComments: ${TOTAL_COMMENTS}\\nErrors: ${ERRORS_COUNT}\\nDuration: ${TASK_DURATION}s\\n\\nðŸ“ Generated Files:\\nJSON files: ${JSON_COUNT}\\nData size: ${TOTAL_SIZE}"
            curl -X POST "$FEISHU_WEBHOOK_URL" \
              -H "Content-Type: application/json" \
              -d "{\"msg_type\":\"text\",\"content\":{\"text\":\"$SUCCESS_MSG\"}}" \
              || echo "Failed to send Feishu notification"
          fi
        fi
        
    - name: Commit and push data
      run: |
        # Determine task type for commit message
        CURRENT_HOUR=$(date -u +%H)
        if [ "$CURRENT_HOUR" = "00" ]; then
          TASK_EMOJI="ðŸŒ…"
          TASK_TYPE="Morning"
        else
          TASK_EMOJI="ðŸŒ™"
          TASK_TYPE="Evening"
        fi
        
        # Check if data directory exists and has files
        if [ -d "data/" ] && [ "$(find data/ -type f | wc -l)" -gt 0 ]; then
          git add data/
          if ! git diff --staged --quiet; then
            git commit -m "${TASK_EMOJI} ${TASK_TYPE} data collection - $(date '+%Y-%m-%d %H:%M:%S')"
            git push
            echo "âœ… Data committed and pushed successfully"
          else
            echo "â„¹ï¸ No changes to commit in data directory"
          fi
        else
          echo "âš ï¸ Data directory is empty or doesn't exist - no data to commit"
        fi
        
    - name: Prepare and upload cookie management reports
      if: always()
      run: |
        # Create placeholder files if they don't exist
        touch cookie_management_report.json
        touch cookie_cleanup_report.json  
        touch failed_cookies_report.json
        touch cleanup_cookies.sh
        
        # Add basic content to empty files
        [ ! -s cookie_management_report.json ] && echo "{\"status\": \"no_report_generated\", \"timestamp\": \"$(date -u +'%Y-%m-%dT%H:%M:%SZ')\"}" > cookie_management_report.json
        [ ! -s cookie_cleanup_report.json ] && echo "{\"status\": \"no_cleanup_performed\", \"timestamp\": \"$(date -u +'%Y-%m-%dT%H:%M:%SZ')\"}" > cookie_cleanup_report.json
        [ ! -s failed_cookies_report.json ] && echo "{\"failed_cookies\": [], \"timestamp\": \"$(date -u +'%Y-%m-%dT%H:%M:%SZ')\"}" > failed_cookies_report.json
        [ ! -s cleanup_cookies.sh ] && echo "#!/bin/bash\necho \"No cleanup script generated - $(date)\"" > cleanup_cookies.sh
        
    - name: Upload cookie management reports
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: cookie-reports-daily-${{ github.run_number }}
        path: |
          cookie_management_report.json
          cookie_cleanup_report.json
          failed_cookies_report.json
          cleanup_cookies.sh
        retention-days: 30