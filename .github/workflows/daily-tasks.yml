name: Daily Data Collection (08:07 & 20:07)

on:
  schedule:
    # UTC 时间 00:07 = 北京时间 08:07
    - cron: '7 0 * * *'
    # UTC 时间 12:07 = 北京时间 20:07
    - cron: '7 12 * * *'
  workflow_dispatch:

permissions:
  contents: write
  actions: read

# 防止并发执行
concurrency:
  group: daily-data-collection-${{ github.ref }}
  cancel-in-progress: true

jobs:
  daily-data-collection:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0
        ref: sync-current-files  # Explicitly checkout the latest sync-current-files branch
      
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Cache cookie usage history
      uses: actions/cache@v3
      with:
        path: ~/.cache/bilibili-cookie-usage-history.json
        key: cookie-usage-${{ runner.os }}-${{ github.repository }}-v1
        restore-keys: |
          cookie-usage-${{ runner.os }}-${{ github.repository }}-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Install Playwright browsers
      run: |
        playwright install chromium
        
    - name: Configure git for data conflicts
      run: |
        git config --global user.name "GitHub Actions"
        git config --global user.email "actions@github.com"
        # Configure git to handle database file conflicts
        git config merge.ours.driver true
        echo "data/database/bilibili_tracking.db merge=ours" >> .gitattributes
        git add .gitattributes || true
        
        # Ensure we're on the latest version before starting tasks
        echo "🔄 Ensuring latest codebase..."
        git fetch origin sync-current-files
        git reset --hard origin/sync-current-files
        
    - name: Enhanced cookie rotation and selection
      env:
        UP_ID: ${{ secrets.UP_ID }}
        BILIBILI_COOKIES: ${{ secrets.BILIBILI_COOKIES }}
        BILIBILI_COOKIES_1: ${{ secrets.BILIBILI_COOKIES_1 }}
        BILIBILI_COOKIES_2: ${{ secrets.BILIBILI_COOKIES_2 }}
        BILIBILI_COOKIES_3: ${{ secrets.BILIBILI_COOKIES_3 }}
        BILIBILI_COOKIES_4: ${{ secrets.BILIBILI_COOKIES_4 }}
        BILIBILI_COOKIES_5: ${{ secrets.BILIBILI_COOKIES_5 }}
        BILIBILI_COOKIES_6: ${{ secrets.BILIBILI_COOKIES_6 }}
        BILIBILI_COOKIES_7: ${{ secrets.BILIBILI_COOKIES_7 }}
        BILIBILI_COOKIES_8: ${{ secrets.BILIBILI_COOKIES_8 }}
        BILIBILI_COOKIES_9: ${{ secrets.BILIBILI_COOKIES_9 }}
        BILIBILI_COOKIES_10: ${{ secrets.BILIBILI_COOKIES_10 }}
      run: |
        echo "🔄 Starting unified cookie rotation with enhanced statistics"
        python .github/scripts/unified_cookie_manager.py rotation
        
    - name: Cookie cleanup check
      if: always()
      env:
        BILIBILI_COOKIES: ${{ secrets.BILIBILI_COOKIES }}
        BILIBILI_COOKIES_1: ${{ secrets.BILIBILI_COOKIES_1 }}
        BILIBILI_COOKIES_2: ${{ secrets.BILIBILI_COOKIES_2 }}
        BILIBILI_COOKIES_3: ${{ secrets.BILIBILI_COOKIES_3 }}
        BILIBILI_COOKIES_4: ${{ secrets.BILIBILI_COOKIES_4 }}
        BILIBILI_COOKIES_5: ${{ secrets.BILIBILI_COOKIES_5 }}
        BILIBILI_COOKIES_6: ${{ secrets.BILIBILI_COOKIES_6 }}
        BILIBILI_COOKIES_7: ${{ secrets.BILIBILI_COOKIES_7 }}
        BILIBILI_COOKIES_8: ${{ secrets.BILIBILI_COOKIES_8 }}
        BILIBILI_COOKIES_9: ${{ secrets.BILIBILI_COOKIES_9 }}
        BILIBILI_COOKIES_10: ${{ secrets.BILIBILI_COOKIES_10 }}
      run: |
        echo "🗑️ Checking for failed cookies cleanup"
        python .github/scripts/unified_cookie_manager.py cleanup || echo "Cleanup check completed with warnings"
        
    - name: Run daily data collection with notification
      env:
        UP_ID: ${{ secrets.UP_ID }}
        FEISHU_WEBHOOK_URL: ${{ secrets.FEISHU_WEBHOOK_URL }}
        PYTHONPATH: ${{ github.workspace }}
        GITHUB_RUN_NUMBER: ${{ github.run_number }}
        GITHUB_REF_NAME: ${{ github.ref_name }}
        GITHUB_REPOSITORY: ${{ github.repository }}
        # Add Cookie environment variables for data collection
        BILIBILI_COOKIES: ${{ secrets.BILIBILI_COOKIES }}
        BILIBILI_COOKIES_1: ${{ secrets.BILIBILI_COOKIES_1 }}
        BILIBILI_COOKIES_2: ${{ secrets.BILIBILI_COOKIES_2 }}
        BILIBILI_COOKIES_3: ${{ secrets.BILIBILI_COOKIES_3 }}
        BILIBILI_COOKIES_4: ${{ secrets.BILIBILI_COOKIES_4 }}
        BILIBILI_COOKIES_5: ${{ secrets.BILIBILI_COOKIES_5 }}
        BILIBILI_COOKIES_6: ${{ secrets.BILIBILI_COOKIES_6 }}
        BILIBILI_COOKIES_7: ${{ secrets.BILIBILI_COOKIES_7 }}
        BILIBILI_COOKIES_8: ${{ secrets.BILIBILI_COOKIES_8 }}
        BILIBILI_COOKIES_9: ${{ secrets.BILIBILI_COOKIES_9 }}
        BILIBILI_COOKIES_10: ${{ secrets.BILIBILI_COOKIES_10 }}
      run: |
        echo "Starting daily data collection"
        
        # Determine task type based on trigger method
        if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          # Manual trigger - use Manual type
          TASK_TYPE="Manual"
          TASK_EMOJI="🔧"
          echo "Manual execution detected"
        else
          # Scheduled trigger - determine by UTC time
          CURRENT_HOUR=$(date -u +%H)
          if [ "$CURRENT_HOUR" = "00" ]; then
            TASK_TYPE="Morning"
            TASK_EMOJI="🌅"
          else
            TASK_TYPE="Evening"
            TASK_EMOJI="🌙"
          fi
        fi
        
        echo "Task type: $TASK_TYPE ($TASK_EMOJI)"
        
        # Run daily task and capture all output
        echo "Running daily task..."
        TASK_OUTPUT_FILE="task_output_$(date +%s).log"
        
        if python run_daily_task.py > "$TASK_OUTPUT_FILE" 2>&1; then
          TASK_EXIT_CODE=0
          echo "✅ Daily task completed successfully"
          
          # Send success notification with extracted data
          echo "Sending success notification..."
          python .github/scripts/feishu_notifier.py "$TASK_TYPE Daily Data Collection" "success" < "$TASK_OUTPUT_FILE" || echo "⚠️ Notification failed but task succeeded"
          
        else
          TASK_EXIT_CODE=1
          echo "❌ Daily task failed"
          
          # Send failure notification with extracted data
          echo "Sending failure notification..."
          python .github/scripts/feishu_notifier.py "$TASK_TYPE Daily Data Collection" "failure" < "$TASK_OUTPUT_FILE" || echo "⚠️ Notification failed and task failed"
          
          # Display output for debugging
          echo "=== Task Output ==="
          cat "$TASK_OUTPUT_FILE"
          echo "=================="
          
          exit 1
        fi
        
        # Display output for debugging (success case)
        echo "=== Task Output ==="
        cat "$TASK_OUTPUT_FILE"
        echo "=================="
        
        # Cleanup
        rm -f "$TASK_OUTPUT_FILE"
        
    - name: Commit and push data
      run: |
        # Determine task type for commit message (same logic as above)
        if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          TASK_EMOJI="🔧"
          TASK_TYPE="Manual"
        else
          CURRENT_HOUR=$(date -u +%H)
          if [ "$CURRENT_HOUR" = "00" ]; then
            TASK_EMOJI="🌅"
            TASK_TYPE="Morning"
          else
            TASK_EMOJI="🌙"
            TASK_TYPE="Evening"
          fi
        fi
        
        # Check if data directory exists and has files
        if [ -d "data/" ] && [ "$(find data/ -type f | wc -l)" -gt 0 ]; then
          echo "📊 Found data files to commit"
          
          # Check if we have any changes to stash
          if ! git diff --quiet || ! git diff --cached --quiet || [ -n "$(git ls-files --others --exclude-standard)" ]; then
            echo "💾 Stashing local changes before sync..."
            git add data/ || true  # Add data files to index first
            git stash push -u -m "Temporary stash before pull - $(date)" || echo "Nothing to stash"
          fi
          
          # Fetch and pull the latest changes
          echo "🔄 Syncing with remote repository..."
          git fetch origin sync-current-files
          git pull origin sync-current-files --no-edit || echo "No remote changes to pull"
          
          # Restore our stashed changes if any
          if git stash list | grep -q "Temporary stash before pull"; then
            echo "📂 Restoring local changes..."
            git stash pop || {
              echo "⚠️ Merge conflict detected, resolving automatically..."
              # For database files, prefer the local version (newly generated)
              git checkout --ours data/database/bilibili_tracking.db 2>/dev/null || true
              # Add all data files
              git add data/ || true
              # Drop the problematic stash
              git stash drop || true
              echo "✅ Conflicts resolved"
            }
          fi
          
          git add data/
          if ! git diff --staged --quiet; then
            git commit -m "${TASK_EMOJI} ${TASK_TYPE} data collection - $(date '+%Y-%m-%d %H:%M:%S')"
            
            # Try to push, with retry mechanism for conflicts
            MAX_RETRIES=3
            RETRY_COUNT=0
            
            while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
              if git push origin sync-current-files; then
                echo "✅ Data committed and pushed successfully"
                break
              else
                RETRY_COUNT=$((RETRY_COUNT + 1))
                echo "⚠️ Push failed (attempt $RETRY_COUNT/$MAX_RETRIES), trying to resolve..."
                
                if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                  # Fetch and rebase for the retry
                  git fetch origin sync-current-files
                  git rebase origin/sync-current-files || {
                    echo "🔧 Rebase conflict, resolving automatically..."
                    git rebase --abort
                    git pull origin sync-current-files --no-edit --strategy-option=ours
                  }
                else
                  echo "❌ Failed to push after $MAX_RETRIES attempts"
                  exit 1
                fi
              fi
            done
          else
            echo "ℹ️ No changes to commit in data directory"
          fi
        else
          echo "⚠️ Data directory is empty or doesn't exist - no data to commit"
        fi
        
    - name: Prepare and upload cookie management reports
      if: always()
      run: |
        # Create placeholder files if they don't exist
        touch cookie_management_report.json
        touch cookie_cleanup_report.json  
        touch failed_cookies_report.json
        touch cleanup_cookies.sh
        
        # Add basic content to empty files
        [ ! -s cookie_management_report.json ] && echo "{\"status\": \"no_report_generated\", \"timestamp\": \"$(date -u +'%Y-%m-%dT%H:%M:%SZ')\"}" > cookie_management_report.json
        [ ! -s cookie_cleanup_report.json ] && echo "{\"status\": \"no_cleanup_performed\", \"timestamp\": \"$(date -u +'%Y-%m-%dT%H:%M:%SZ')\"}" > cookie_cleanup_report.json
        [ ! -s failed_cookies_report.json ] && echo "{\"failed_cookies\": [], \"timestamp\": \"$(date -u +'%Y-%m-%dT%H:%M:%SZ')\"}" > failed_cookies_report.json
        [ ! -s cleanup_cookies.sh ] && echo "#!/bin/bash\necho \"No cleanup script generated - $(date)\"" > cleanup_cookies.sh
        
    - name: Upload cookie management reports
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: cookie-reports-daily-${{ github.run_number }}
        path: |
          cookie_management_report.json
          cookie_cleanup_report.json
          failed_cookies_report.json
          cleanup_cookies.sh
        retention-days: 30